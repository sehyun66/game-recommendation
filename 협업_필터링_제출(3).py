# -*- coding: utf-8 -*-
"""협업 필터링 제출(3)의 사본

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Id5i7uQcNmzMydcAPrdEjcKPuxwnIYGy
"""

# Commented out IPython magic to ensure Python compatibility.
## 코랩을 사용할 때
#드라이브 마운트
from google.colab import drive
drive.mount('/content/drive')

#현재 작업 위치 이동
#띄어쓰기에 \붙일 것
# %cd /content/drive/MyDrive/MultiCampus/데이터 시각화3

import pickle
import pandas as pd

similarity_rate2 = pd.read_pickle('gamedata.pkl')# 피클로 저장된 파일 불러오기

def recommend_game(appid, top_n): 
  '''게임추천 모델
  appid: 게임 고유 코드
  top_n: 추천 받을 게임 개수
  '''
  rec_game=similarity_rate2[appid].reset_index()
  rec_game = rec_game.rename(columns={"appid": "game",appid:'similarity'})
  rec_game=rec_game.sort_values(by='similarity',ascending=False).head(top_n)

  return rec_game

# game1, game2, game3 추천 게임 - 유사도 테이블
def gentleman_ver2(game1, game2, game3):
  d1 = pd.DataFrame(recommend_game(game1, top_n=10), columns=['game', 'similarity']) # game1 추천목록 & 유사도
  d2 = pd.DataFrame(recommend_game(game2, top_n=10), columns=['game', 'similarity']) # game2 추천목록 & 유사도
  d3 = pd.DataFrame(recommend_game(game3, top_n=10), columns=['game', 'similarity']) # game3 추천목록 & 유사도
  df = pd.merge(d1, d2, on='game', how='outer') # d1, d2 merge
  df = pd.merge(df, d3, on='game', how='outer') # d2, d3 merge

  for game in df['game']: # ['game'] 행 하나씩 돌면서 
   if game in [game1, game2, game3]: # game이 game1, game2, game3에 해당하는 경우
      drop_index = df[df['game']==game].index
      df.drop(drop_index, axis='index', inplace=True) # 해당 행 drop

  # 추천 리스트 간 중복되는 게임이 없는 경우 각 추천리스트에서 2개씩 뽑음
  if len(df) == 30: 
    return [x for x in  recommend_game(game1, top_n=2)['game'].unique()]+ [x for x in recommend_game(game2, top_n=2)['game'].unique()] 
    + [x for x in recommend_game(game3, top_n=2)['game'].unique()]
  # 유사도 평균 내서 상위 6개 추출
  else : 
    df.fillna(0, inplace=True)
    df['mean'] = df.mean(axis=1, numeric_only=True)
    df.sort_values('mean', ascending=False, inplace=True)
    return list(df['game'][:6])

print(gentleman_ver2(240,3010,1225780))

!pip install surprise

from surprise.model_selection import GridSearchCV
from surprise import Dataset, Reader
import joblib

df_steam_meta_con = pd.read_pickle('steam_meta.pkl')
reader=Reader(rating_scale=(0,10))
data = Dataset.load_from_df(df_steam_meta_con[['appid','user','userscore']],
                           reader=reader)

trainset = data.build_full_trainset()
testset = trainset.build_testset()
def grid_search():	
	param_grid = {'n_epochs': [5, 10, 15], 'lr_all': [0.002, 0.004, 0.006],
	              'reg_all': [0.4, 0.6, 0.8]}
	gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=5)
	
	gs.fit(data)
	
	# best RMSE score
	print(gs.best_score['rmse'])
	
	# combination of parameters that gave the best RMSE score
	print(gs.best_params['rmse'])

joblib.dump(gs, 'gs.pkl')
df_gs=joblib.load("gs.pkl")
df_gs.best_score['rmse'], df_gs.best_params['rmse']

!pip install bayesian-optimization
from bayes_opt import BayesianOptimization
from surprise.model_selection import PredefinedKFold
from surprise.model_selection import KFold

def svd(n_factors, init_mean, init_std_dev, lr_all, reg_all ):
	params = {'n_factors' : n_factors,
		 'init_mean': init_mean, 'init_std_dev': init_std_dev,
		 'lr_all': lr_all, 'reg_all':reg_all}

	svd_algo = SVD(n_factors= int(params['n_factors']), n_epochs=10,
			init_mean= params['init_mean'],
			init_std_dev=params['init_std_dev'],
			lr_all=params['lr_all'],
			reg_all=params['reg_all'])
	
	rmse=cross_validate(svd_algo, data, measures=['RMSE'], cv=5)
	mean_rmse = rmse['test_rmse'].mean()
	return 1-mean_rmse

svd_Bay=BayesianOptimization(svd, {'n_factors':(int(150), int(180)),
				'init_mean':(0,0.65),
				'init_std_dev':(0.1,0.3),
				'lr_all':(0.015,0.035),
				'reg_all':(0.05,0.085)})
svd_Bay.maximize(init_points=5, n_iter=20, xi=0.02)
print('-' * 50)
print('Final Results')
print(svd_Bay.max)

